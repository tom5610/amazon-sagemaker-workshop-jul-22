{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10 Image Classification with TFRecord Dataset\n",
    "\n",
    "For this exercise notebook, you should be able to use the `Python 3 (TensorFlow 2.6 Python 3.8 CPU Optimized)` kernel on SageMaker Studio, or `conda_tensorflow2_p38` on classic SageMaker Notebook Instances.\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Your new colleague in the data science team (who isn't very familiar with SageMaker) has written a nice notebook to tackle an image classification problem with Keras: [Local Notebook.ipynb](Local%20Notebook.ipynb).\n",
    "\n",
    "It works OK with the simple CIFAR10 data set they were working on before, but now they'd like to take advantage of some of the features of SageMaker to tackle bigger and harder challenges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from functools import partial\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import random\n",
    "\n",
    "# Python Built-Ins:\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# TensorFlow Keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import sagemaker\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data and Upload to Amazon S3\n",
    "\n",
    "The primary data source for a SageMaker training job is (nearly) always S3 - so we should upload our training and test data there.\n",
    "\n",
    "For this exercise, we prepared a few lines of code below to help you upload the images to Amazon S3 using the [aws s3 cp](https://docs.aws.amazon.com/cli/latest/reference/s3/cp.html) CLI command.\n",
    "\n",
    "But first, let's download the image data from the Repository of Open Data on AWS and sample a subset like we did in the [Local Notebook.ipynb](Local%20Notebook.ipynb).\n",
    "\n",
    "**Check you understand** what data it's going to upload from this notebook, and where it's going to store it in S3, then start the upload running.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://fast-ai-imageclas/cifar10.tgz to ../../../tmp/cifar10/cifar10.tgz\n",
      "Training files: 50000\n",
      "Testing files:  10000\n"
     ]
    }
   ],
   "source": [
    "target_path = \"/tmp/cifar10\"\n",
    "training_dir = f\"{target_path}/train\"\n",
    "testing_dir = f\"{target_path}/test\"\n",
    "\n",
    "# Download the CIFAR10 data from the Registry of Open Data on AWS\n",
    "!rm -rf {target_path}\n",
    "!mkdir -p {target_path}\n",
    "!aws s3 cp s3://fast-ai-imageclas/cifar10.tgz {target_path} --no-sign-request\n",
    "\n",
    "# Un-tar the CIFAR10 data, stripping the leading path element; this will leave us with directories\n",
    "# {target_path}/testing/ and {target_path/training/\n",
    "!tar zxf {target_path}/cifar10.tgz -C {target_path}/ --strip-components=1 --no-same-owner\n",
    "!rm -f {target_path}/cifar10.tgz\n",
    "\n",
    "# Get the list of files in the training and testing directories recursively\n",
    "train_files = sorted(list(glob.iglob(os.path.join(training_dir, \"*/*.png\"), recursive=True)))\n",
    "test_files = sorted(list(glob.iglob(os.path.join(testing_dir, \"*/*.png\"), recursive=True)))\n",
    "\n",
    "print(f\"Training files: {len(train_files)}\")\n",
    "print(f\"Testing files:  {len(test_files)}\")\n",
    "\n",
    "random.shuffle(train_files)\n",
    "random.shuffle(test_files)\n",
    "\n",
    "labels = sorted(os.listdir(training_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the local 'opt ml' directories so that we can run the training script.\n",
    "local_opt_ml_dir = '/tmp/local_opt_ml'\n",
    "local_input_train_channel_dir = f\"{local_opt_ml_dir}/input/data/train\"\n",
    "local_input_test_channel_dir = f\"{local_opt_ml_dir}/input/data/test\"\n",
    "local_model_dir = f\"{local_opt_ml_dir}/model\"\n",
    "local_output_dir = f\"{local_opt_ml_dir}/output\"\n",
    "\n",
    "!rm -rf {local_opt_ml_dir}\n",
    "!mkdir -p {local_input_train_channel_dir}\n",
    "!mkdir -p {local_input_test_channel_dir}\n",
    "!mkdir -p {local_model_dir}\n",
    "!mkdir -p {local_output_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert *.png to TFRecords files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2VWMHlG3Zgvx"
   },
   "outputs": [],
   "source": [
    "def _bytestring_feature(value):\n",
    "    return tf.train.Feature(\n",
    "        bytes_list=tf.train.BytesList(value=[tf.io.encode_png(value).numpy()])\n",
    "    )\n",
    "\n",
    "def _int_feature(list_of_ints): # int64\n",
    "      return tf.train.Feature(int64_list=tf.train.Int64List(value=list_of_ints))\n",
    "\n",
    "def _float_feature(list_of_floats): # float32\n",
    "      return tf.train.Feature(float_list=tf.train.FloatList(value=list_of_floats))\n",
    "\n",
    "def create_example(img_bytes, label):    \n",
    "    feature = {\n",
    "      \"image\": _bytestring_feature(img_bytes), # one image in the list\n",
    "      \"class\": _int_feature([label]),        # one class in the list      \n",
    "    }\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the *.png files to TFRecords\n",
    "def convert_png_to_tfrecord(image_files, target_file):\n",
    "    with tf.io.TFRecordWriter(target_file) as writer:\n",
    "        for file in image_files:\n",
    "            category = file.split('/')[-2] # \n",
    "            label = labels.index(category)\n",
    "            # print(f\"{label} - {file}\")\n",
    "            image = tf.io.decode_png(tf.io.read_file(file)) \n",
    "            example = create_example(image, label)\n",
    "            writer.write(example.SerializeToString())\n",
    "\n",
    "train_tfrec_filename = f'{local_input_train_channel_dir}/cifar10-train.tfrec'\n",
    "convert_png_to_tfrecord(train_files, train_tfrec_filename)\n",
    "\n",
    "test_tfrec_filename = f'{local_input_test_channel_dir}/cifar10-test.tfrec'\n",
    "convert_png_to_tfrecord(test_files, test_tfrec_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 111M\n",
      "drwxr-xr-x 2 root root   33 Aug  3 03:54 .\n",
      "drwxr-xr-x 4 root root   31 Aug  3 03:26 ..\n",
      "-rw-r--r-- 1 root root 111M Aug  3 04:02 cifar10-train.tfrec\n"
     ]
    }
   ],
   "source": [
    "!ls -lah {local_input_train_channel_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 23M\n",
      "drwxr-xr-x 2 root root  32 Aug  3 04:02 .\n",
      "drwxr-xr-x 4 root root  31 Aug  3 03:26 ..\n",
      "-rw-r--r-- 1 root root 23M Aug  3 04:02 cifar10-test.tfrec\n"
     ]
    }
   ],
   "source": [
    "!ls -lah {local_input_test_channel_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data file and prepare for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurable variables\n",
    "AUTO = tf.data.experimental.AUTOTUNE # used in tf.data.Dataset API\n",
    "BATCH_SIZE = 128\n",
    "INPUT_SHAPE = (32, 32, 3)\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_filenames = tf.io.gfile.glob(f\"{local_input_train_channel_dir}/*.tfrec\")\n",
    "validation_filenames = tf.io.gfile.glob(f\"{local_input_test_channel_dir}/*.tfrec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "6R4tj1g4ioE_"
   },
   "outputs": [],
   "source": [
    "def read_tfrecord(example):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),  # tf.string = bytestring (not text string)\n",
    "        \"class\": tf.io.FixedLenFeature([], tf.int64),   # shape [] means scalar\n",
    "    }\n",
    "    # decode the TFRecord\n",
    "    example = tf.io.parse_single_example(example, features)\n",
    "    \n",
    "    image = tf.image.decode_png(example['image'], channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    # image = tf.reshape(image, [32,32, 3])\n",
    "    \n",
    "    class_label = tf.cast(example['class'], tf.int32)\n",
    "    \n",
    "    return image, class_label\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "NbZuB981ioHY"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_batched_dataset(filenames):\n",
    "    option_no_order = tf.data.Options()\n",
    "    option_no_order.experimental_deterministic = False\n",
    "\n",
    "    dataset = tf.data.Dataset.list_files(filenames)\n",
    "    dataset = dataset.with_options(option_no_order)\n",
    "    dataset = dataset.interleave(tf.data.TFRecordDataset, cycle_length=16, num_parallel_calls=AUTO)\n",
    "    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTO)\n",
    "\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True) # drop_remainder will be needed on TPU\n",
    "    dataset = dataset.prefetch(AUTO) #\n",
    "\n",
    "    return dataset\n",
    "  \n",
    "def get_training_dataset():\n",
    "    return get_batched_dataset(training_filenames)\n",
    "\n",
    "def get_validation_dataset():\n",
    "    return get_batched_dataset(validation_filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=INPUT_SHAPE))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(labels), activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "aU9tZWhTU7A9",
    "outputId": "ecfc7255-f976-4422-a322-9b9162421f0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Extension horovod.torch has not been built: /usr/local/lib/python3.8/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-38-x86_64-linux-gnu.so not found\n",
      "If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\n",
      "Warning! MPI libs are missing, but python applications are still avaiable.\n",
      "[2022-08-03 04:17:13.952 tensorflow-2-6-cpu-py3-ml-m5-large-b6c8fce23e41089ce72f77da84d4:1948 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2022-08-03 04:17:14.007 tensorflow-2-6-cpu-py3-ml-m5-large-b6c8fce23e41089ce72f77da84d4:1948 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "390/390 - 125s - loss: 1.7605 - accuracy: 0.3461 - val_loss: 1.3681 - val_accuracy: 0.4959\n",
      "Epoch 2/5\n",
      "390/390 - 123s - loss: 1.2879 - accuracy: 0.5377 - val_loss: 1.0565 - val_accuracy: 0.6188\n",
      "Epoch 3/5\n",
      "390/390 - 126s - loss: 1.0695 - accuracy: 0.6246 - val_loss: 0.9279 - val_accuracy: 0.6730\n",
      "Epoch 4/5\n",
      "390/390 - 128s - loss: 0.9397 - accuracy: 0.6713 - val_loss: 0.8354 - val_accuracy: 0.7061\n",
      "Epoch 5/5\n",
      "390/390 - 123s - loss: 0.8410 - accuracy: 0.7068 - val_loss: 0.7648 - val_accuracy: 0.7302\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    get_training_dataset(), \n",
    "    epochs=EPOCHS,\n",
    "    validation_data=get_validation_dataset(), \n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 7s 89ms/step - loss: 0.7642 - accuracy: 0.7304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7641528844833374, 0.7303686141967773]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = model.evaluate(get_validation_dataset()) \n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker Section\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "bucket_name = sess.default_bucket()  # We'll just use the default bucket as the other examples did"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To verify the model training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-03 04:38:29.218651: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "2022-08-03 04:38:29.218769: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n",
      "2022-08-03 04:38:29.245473: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "Namespace(batch_size=128, epochs=1, model_dir='/tmp/local_opt_ml/model', output_data_dir='/tmp/local_opt_ml/output', test='/tmp/local_opt_ml/input/data/test', train='/tmp/local_opt_ml/input/data/train')\n",
      "Loading dataset...\n",
      "training dataset: ['/tmp/local_opt_ml/input/data/train/cifar10-train.tfrec']\n",
      "2022-08-03 04:38:30.600142: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-03 04:38:30.602154: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "validation dataset: ['/tmp/local_opt_ml/input/data/test/cifar10-test.tfrec']\n",
      "Building a model...\n",
      "Fitting the data...\n",
      "Extension horovod.torch has not been built: /usr/local/lib/python3.8/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-38-x86_64-linux-gnu.so not found\n",
      "If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\n",
      "Warning! MPI libs are missing, but python applications are still avaiable.\n",
      "[2022-08-03 04:38:31.180 tensorflow-2-6-cpu-py3-ml-m5-large-b6c8fce23e41089ce72f77da84d4:3234 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2022-08-03 04:38:31.350 tensorflow-2-6-cpu-py3-ml-m5-large-b6c8fce23e41089ce72f77da84d4:3234 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "2022-08-03 04:38:31.723030: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "390/390 - 126s - loss: 1.7342 - accuracy: 0.3576 - val_loss: 1.3147 - val_accuracy: 0.5152\n",
      "78/78 [==============================] - 7s 93ms/step - loss: 1.3151 - accuracy: 0.5154\n",
      "Test loss: 1.3151189088821411\n",
      "Test accuracy: 0.5154246687889099\n",
      "2022-08-03 04:40:45.160359: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "INFO:tensorflow:Assets written to: /tmp/local_opt_ml/model/model/1/assets\n",
      "INFO:tensorflow:Assets written to: /tmp/local_opt_ml/model/model/1/assets\n"
     ]
    }
   ],
   "source": [
    "!python3 src/main_tfrec.py --train {local_input_train_channel_dir} --test {local_input_test_channel_dir} --output-data-dir {local_output_dir} --model-dir {local_model_dir} --epochs=1 --batch-size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_train_uri = f\"s3://{bucket_name}/cifar10/tfrecords/train\"\n",
    "s3_test_uri = f\"s3://{bucket_name}/cifar10/tfrecords/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload data to S3\n",
    "!aws s3 sync --quiet --delete {local_input_train_channel_dir} {s3_train_uri}\n",
    "\n",
    "!aws s3 sync --quiet --delete {local_input_test_channel_dir} {s3_test_uri}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup input channel for model training on SageMaker Training Job\n",
    "input_mode = 'FastFile' # 'FastFile' is not suitable on the use case given the dataset is with many small files. (< 50MB)\n",
    "\n",
    "train_channel = sagemaker.inputs.TrainingInput(s3_train_uri, input_mode=input_mode)\n",
    "test_channel = sagemaker.inputs.TrainingInput(s3_test_uri, input_mode=input_mode)\n",
    "\n",
    "inputs = { \"train\": train_channel, \"test\": test_channel }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TensorFlow(\n",
    "    role=role,  # IAM role to run the job under - we just use the same as the notebook role\n",
    "    \n",
    "    # Framework setup:\n",
    "    entry_point=\"main_tfrec.py\",  # Target script\n",
    "    source_dir=\"./src\",  # Folder to bundle, in case we want to split the code between files\n",
    "    framework_version=\"2.5\",  # TensorFlow version\n",
    "    py_version=\"py37\",  # The time to migrate away from Python 2 has long ago passed!\n",
    "\n",
    "    # Infrastructure provisioning:\n",
    "    instance_count=1,  # We haven't implemented parallelization in our script\n",
    "    instance_type=\"ml.m5.xlarge\",  # Keras should be accelerated by GPU 'ml.g4dn.xlarge'\n",
    "    max_run=20*60, # The training shouldn't take too long to run\n",
    "    # use_spot_instances=True,  # May as well use spot to save money\n",
    "    # max_wait=40*60,  # ...And we don't want to wait for ages for spot instances\n",
    "    \n",
    "    # Parameters to pass to our script:\n",
    "    hyperparameters={\n",
    "        \"epochs\": 5, \n",
    "        \"batch-size\": 256,\n",
    "    },\n",
    "    \n",
    "    # Performance/progress metrics to scrape from console output:\n",
    "    metric_definitions=[\n",
    "        { \"Name\": \"loss\", \"Regex\": \"loss: ([0-9\\\\.]+)\" },\n",
    "        { \"Name\": \"accuracy\", \"Regex\": \"acc: ([0-9\\\\.]+)\" },\n",
    "        { \"Name\": \"test:loss\", \"Regex\": \"Test.*loss=([0-9\\\\.]+)\" },\n",
    "        { \"Name\": \"test:accuracy\", \"Regex\": \"Test.*accuracy=([0-9\\\\.]+)\" },\n",
    "    ],\n",
    "    \n",
    "    # Let's keep our SageMaker records tidy by giving the training jobs a sensible name\n",
    "    base_job_name=\"cifar10-keras-tfrec\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To kick off SageMaker Training Job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: cifar10-keras-tfrec-2022-08-03-04-44-01-816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-03 04:44:02 Starting - Starting the training job...\n",
      "2022-08-03 04:44:26 Starting - Preparing the instances for trainingProfilerReport-1659501842: InProgress\n",
      "......\n",
      "2022-08-03 04:45:26 Downloading - Downloading input data...\n",
      "2022-08-03 04:45:46 Training - Downloading the training image.."
     ]
    }
   ],
   "source": [
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "feed own data.ipynb",
   "provenance": []
  },
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.6 Python 3.8 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-2:452832661640:image/tensorflow-2.6-cpu-py38-ubuntu20.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
