{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10 Image Classification with Local\n",
    "\n",
    "_**Train and export a TF.Keras CNN classifier for (a subset of) the [CIFAR10](https://en.wikipedia.org/wiki/CIFAR-10) dataset: Performing all storage and computation locally on the notebook.**_\n",
    "\n",
    "This notebook works well with the `Python 3 (TensorFlow 2.3 Python 3.7 CPU Optimized)` kernel on SageMaker Studio, or `conda_tensorflow2_p38` on classic SageMaker Notebook Instances. Especially, please select 'ml.m5.large' as the SageMaker Studio Notebook instance with click `# vCPU + # GiB` (`#` is the figure of amount of vCPU and GiB on the instance) button at the top of the notebook. \n",
    "\n",
    "---\n",
    "\n",
    "The [dataset](https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz) is hosted in the [Registry of Open Data on AWS](https://registry.opendata.aws/fast-ai-imageclas/) and contains PNG images organized in folders by which object they represent.\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. **[Prepare the Data](#Prepare-the-Data)**\n",
    "1. **[Load the Data From File](#Load-the-Data-From-File)**\n",
    "1. **[Pre-Process the Data for our CNN](#Pre-Process-the-Data-for-our-CNN)**\n",
    "1. **[Build a Model](#Build-a-Model)**\n",
    "1. **[Fit the Model](#Fit-the-Model)**\n",
    "1. **[Save the Trained Model](#Save-the-Trained-Model)**\n",
    "1. **[Explore Results](#Explore-Results)**\n",
    "\n",
    "See the accompanying **Instructions** notebook for more guidance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First install some libraries which might not be available across all kernels (e.g. in Studio):\n",
    "!pip install ipywidgets matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"Using TensorFlow version {tf.__version__}\") # TensorFlow version should be v2.x\n",
    "print(f\"Keras version {tf.keras.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data\n",
    "\n",
    "Now let's download the image data.\n",
    "\n",
    "The original CIFAR10 data has 60,000 small 32X32X3 pixel PNG files (50,000 in the training dataset, and 10,000 in the test dataset). This format is nice and familiar - but a large number of tiny files is inefficient for storage and transfer - so **to keep things performant** we will:\n",
    "\n",
    "- Download the data to a local temporary folder under `/tmp` (meaning you won't see the files in the left sidebar in SageMaker)\n",
    "- Sample just a subset of the data to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_path = \"/tmp/cifar10\"\n",
    "training_dir = f\"{target_path}/train\"\n",
    "testing_dir = f\"{target_path}/test\"\n",
    "\n",
    "# Download the CIFAR10 data from the Registry of Open Data on AWS\n",
    "!rm -rf {target_path}\n",
    "!mkdir -p {target_path}\n",
    "!aws s3 cp s3://fast-ai-imageclas/cifar10.tgz {target_path} --no-sign-request\n",
    "\n",
    "# Un-tar the CIFAR10 data, stripping the leading path element; this will leave us with directories\n",
    "# {target_path}/testing/ and {target_path/training/\n",
    "!tar zxf {target_path}/cifar10.tgz -C {target_path}/ --strip-components=1 --no-same-owner\n",
    "!rm -f {target_path}/cifar10.tgz\n",
    "\n",
    "# Get the list of files in the training and testing directories recursively\n",
    "train_files = sorted(list(glob.iglob(os.path.join(training_dir, \"*/*.png\"), recursive=True)))\n",
    "test_files = sorted(list(glob.iglob(os.path.join(testing_dir, \"*/*.png\"), recursive=True)))\n",
    "\n",
    "print(f\"Training files: {len(train_files)}\")\n",
    "print(f\"Testing files:  {len(test_files)}\")\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the data by keeping every Nth file and dropping the rest of the files.\n",
    "# In our exercise, keeping reduction_factor as 1 to include all data.\n",
    "# reduction_factor = 1\n",
    "# train_files_to_keep = train_files[::reduction_factor]\n",
    "# test_files_to_keep = test_files[::reduction_factor]\n",
    "\n",
    "# print(f\"Training files kept: {len(train_files_to_keep)}\")\n",
    "# print(f\"Testing files kept:  {len(test_files_to_keep)}\")\n",
    "\n",
    "# # Delete all the files not to be kept\n",
    "# for fname in (set(train_files) ^ set(train_files_to_keep)):\n",
    "#     os.remove(fname)\n",
    "\n",
    "# for fname in (set(test_files) ^ set(test_files_to_keep)):\n",
    "#     os.remove(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Reduced Data From Files\n",
    "\n",
    "Now our images are stored in the `{target_path}` folder, let's read our training and testing sets in from these files.\n",
    "\n",
    "```\n",
    "    {target_path}\n",
    "    |----------------.\n",
    "    `-- test           `-- train\n",
    "        |-- airplane       |-- airplane \n",
    "        |                      `-- 1.png\n",
    "        |-- automobile     |-- automobile   \n",
    "        |-- bird           |-- bird\n",
    "        |-- cat            |-- cat\n",
    "        |-- deer           |-- deer\n",
    "        |-- dog            |-- dog\n",
    "        |-- frog           |-- frog\n",
    "        |-- horse          |-- horse\n",
    "        |-- ship           |-- ship\n",
    "        `-- truck          `-- truck\n",
    "```\n",
    "\n",
    "(For both training and testing) We'll loop through each folder taking the target label (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck) from the folder name and loading each PNG into an image matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "labels = sorted(os.listdir(training_dir))\n",
    "n_labels = len(labels)\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "print(\"Loading label \", end=\"\")\n",
    "for ix_label in range(n_labels):\n",
    "    label_str = labels[ix_label]\n",
    "    print(f\"{label_str}...\", end=\"\")\n",
    "    trainfiles = filter(\n",
    "        lambda s: s.endswith(\".png\"),\n",
    "        os.listdir(os.path.join(training_dir, label_str))\n",
    "    )    \n",
    "\n",
    "    for filename in trainfiles:\n",
    "        # Can't just use tf.keras.preprocessing.image.load_img(), because it doesn't close its file\n",
    "        # handles! So get \"Too many open files\" error... Grr\n",
    "        with open(os.path.join(training_dir, label_str, filename), \"rb\") as imgfile:\n",
    "            x_train.append(\n",
    "                # Squeeze (drop) that extra channel dimension, to be consistent with prev format:\n",
    "                np.squeeze(tf.keras.preprocessing.image.img_to_array(\n",
    "                    Image.open(imgfile)\n",
    "                ))\n",
    "            )\n",
    "            y_train.append(ix_label)\n",
    "\n",
    "    # Repeat for test data:\n",
    "    testfiles = filter(\n",
    "        lambda s: s.endswith(\".png\"),\n",
    "        os.listdir(os.path.join(testing_dir, label_str))\n",
    "    )\n",
    "\n",
    "    for filename in testfiles:\n",
    "        with open(os.path.join(testing_dir, label_str, filename), \"rb\") as imgfile:\n",
    "            x_test.append(\n",
    "                np.squeeze(tf.keras.preprocessing.image.img_to_array(\n",
    "                    Image.open(imgfile)\n",
    "                ))\n",
    "            )\n",
    "            y_test.append(ix_label)\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"Shuffling trainset...\")\n",
    "train_shuffled = [(x_train[ix], y_train[ix]) for ix in range(len(y_train))]\n",
    "np.random.shuffle(train_shuffled)\n",
    "\n",
    "x_train = np.array([datum[0] for datum in train_shuffled])\n",
    "y_train = np.array([datum[1] for datum in train_shuffled])\n",
    "train_shuffled = None\n",
    "\n",
    "print(\"Shuffling testset...\")\n",
    "test_shuffled = [(x_test[ix], y_test[ix]) for ix in range(len(y_test))]\n",
    "np.random.shuffle(test_shuffled)\n",
    "\n",
    "x_test = np.array([datum[0] for datum in test_shuffled])\n",
    "y_test = np.array([datum[1] for datum in test_shuffled])\n",
    "test_shuffled = None\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before we go ahead**, let's just quickly visualize the data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"x_train.shape {x_train.shape}; dtype {x_train.dtype}\")\n",
    "print(f\"y_train.shape {y_train.shape}; dtype {y_train.dtype}\")\n",
    "print(f\"x_test.shape {x_test.shape}; dtype {x_test.dtype}\")\n",
    "print(f\"y_test.shape {y_test.shape}; dtype {y_test.dtype}\")\n",
    "\n",
    "fig = plt.figure(figsize=(14, 3))\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "#plt.hist(x_train_raw.flatten())\n",
    "plt.hist(x_train.flatten())\n",
    "ax.set_title(\"Histogram of Training Image Data\")\n",
    "ax.set_ylabel(\"Frequency in Training Set\")\n",
    "ax.set_xlabel(\"Pixel Value\")\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "plt.hist(y_train)\n",
    "ax.set_title(\"Histogram of Training Set Labels\")\n",
    "ax.set_ylabel(\"Frequency in Training Set\")\n",
    "ax.set_xlabel(\"Y Label Value\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the data is pretty evenly distributed between labels 0-9, and our images are encoded by fixed-size 32x32x3 matrices from 0 to 255. Here we will just plot a few examples to get a feel for them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Some example images:\")\n",
    "fig = plt.figure(figsize=(14, 2))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(np.array(x_train[i], np.int32), cmap=plt.cm.binary)\n",
    "    plt.xlabel(labels[y_train[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Process the Data for our CNN\n",
    "\n",
    "Next, we'll tweak this format for our neural network:\n",
    "\n",
    "- Normalizing pixel values to improve the numerical conditioning\n",
    "- One-hot encoding our labels to suit a softmax classifier output of probabilities for each object\n",
    "- Adding both a batch dimension (for processing multiple samples in parallel) and a channel dimension (e.g. as if this were a 3-channel RGB image, except single-channel for grayscale) - as well as the X and Y axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by default, it's channel_last for keras backend data format\n",
    "print(f\"training data set shape: {x_train.shape}\")\n",
    "print(K.image_data_format())\n",
    "\n",
    "# to check whether we want to setup channels_last specificially\n",
    "if 'channels_last' != K.image_data_format():\n",
    "    print(\"use 'channels_last' data format...\")\n",
    "    K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataset matrix to be float32 and normalize them by 255\n",
    "x_train = x_train.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"input_shape:\", input_shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = tf.keras.utils.to_categorical(y_train, n_labels)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, n_labels)\n",
    "\n",
    "print(\"n_labels:\", n_labels)\n",
    "print(\"y_train shape:\", y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Model\n",
    "\n",
    "At its core, the model is a 2D convolutional network with a softmax output layer that'll yield a confidence score for every possible label (e.g. 10 options for object in airplane, automobile, bird, cat, deer, dog, frog, horse, ship & truck).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear session - making re-running in a cleaner state\n",
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=input_shape))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_labels, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Model\n",
    "\n",
    "Keras makes fitting and evaluating the model straightforward enough: We don't have any fancy hooks, and are happy with the default logging:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    shuffle=True,\n",
    "    verbose=1, # Hint: You might prefer =2 for running in SageMaker!\n",
    "    validation_data=(x_test, y_test)\n",
    ")\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Test loss={score[0]}\")\n",
    "print(f\"Test accuracy={score[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss curve\n",
    "plt.figure(figsize=[6, 4])\n",
    "plt.plot(history.history['loss'], 'black', linewidth=2.0)\n",
    "plt.plot(history.history['val_loss'], 'green', linewidth=2.0)\n",
    "plt.legend(['Training Loss', 'Validation Loss'], fontsize=14)\n",
    "plt.xlabel('Epochs', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=10)\n",
    "plt.title('Loss Curves', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[6, 4])\n",
    "plt.plot(history.history['accuracy'], 'black', linewidth=2.0)\n",
    "plt.plot(history.history['val_accuracy'], 'blue', linewidth=2.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'], fontsize=14)\n",
    "plt.xlabel('Epochs', fontsize=10)\n",
    "plt.ylabel('Accuracy', fontsize=10)\n",
    "plt.title('Accuracy Curves', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Trained Model\n",
    "\n",
    "Keras has a built-in `model.save()` command, which in TensorFlow v2 can directly produce TensorFlow Serving-compatible outputs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The export folder needs to be empty, or non-existent\n",
    "!rm -rf data/model/model/1\n",
    "\n",
    "model.save(os.path.join(\"data/model\", \"model/1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Results\n",
    "\n",
    "Let's take a sample image from the test set, predict the label and plot it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an image:\n",
    "label = \"truck\"\n",
    "index = 0\n",
    "filename = os.listdir(f\"{testing_dir}/{label}\")[index]\n",
    "\n",
    "# Load the image:\n",
    "img = tf.keras.preprocessing.image.img_to_array(\n",
    "    Image.open(f\"{testing_dir}/{label}/{filename}\")\n",
    ")\n",
    "img = img / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand out the \"batch\" dimension, and send to the model:\n",
    "result = model.predict(np.expand_dims(img, axis=0))\n",
    "print(f\"Result confidences: {result}\")\n",
    "\n",
    "# Plot the result:\n",
    "plt.figure(figsize=(3, 3))\n",
    "fig = plt.subplot(1, 1, 1)\n",
    "ax = plt.imshow(np.squeeze(img), cmap=\"gray\")\n",
    "fig.set_title(f\"Predicted class: {labels[np.argmax(result[0])]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All done! Let's move on to SageMaker notebook to experience SageMaker Training Job."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.3 Python 3.7 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-2:452832661640:image/tensorflow-2.3-cpu-py37-ubuntu18.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
