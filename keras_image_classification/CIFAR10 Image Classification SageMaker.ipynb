{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REFERENCE SOLUTION: TensorFlow MNIST Lift and Shift Exercise\n",
    "\n",
    "For this exercise notebook, you should be able to use the `Python 3 (TensorFlow 1.15 Python 3.7 CPU Optimized)` kernel on SageMaker Studio, or `conda_tensorflow_p36` on classic SageMaker Notebook Instances.\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Your new colleague in the data science team (who isn't very familiar with SageMaker) has written a nice notebook to tackle an image classification problem with Keras: [Local Notebook.ipynb](Local%20Notebook.ipynb).\n",
    "\n",
    "It works OK with the simple MNIST data set they were working on before, but now they'd like to take advantage of some of the features of SageMaker to tackle bigger and harder challenges.\n",
    "\n",
    "**Can you help refactor the Local Notebook code, to show them how to use SageMaker effectively?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "First, check you can **run the [Local Notebook.ipynb](Local%20Notebook.ipynb) notebook through** - reviewing what steps it takes.\n",
    "\n",
    "**This notebook** sets out a structure you can use to migrate code into, and lists out some of the changes you'll need to make at a high level. You can either work directly in here, or duplicate this notebook so you still have an unchanged copy of the original.\n",
    "\n",
    "Try to work through the sections first with an MVP goal in mind (fitting the model to data in S3 via a SageMaker Training Job, and deploying/using the model through a SageMaker Endpoint). At the end, there are extension exercises to bring in more advanced functionality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "Listing all our imports at the start helps to keep the requirements to run any script/file transparent up-front, and is specified by nearly every style guide including Python's official [PEP 8](https://www.python.org/dev/peps/pep-0008/#imports)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/site-packages (7.7.1)\n",
      "Requirement already satisfied: matplotlib in /root/.local/lib/python3.7/site-packages (3.5.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/site-packages (from ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /root/.local/lib/python3.7/site-packages (from ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/site-packages (from ipywidgets) (5.5.6)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/site-packages (from ipywidgets) (3.6.1)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/site-packages (from ipywidgets) (7.16.3)\n",
      "Requirement already satisfied: tornado>=4.2 in /root/.local/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.5)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (59.3.0)\n",
      "Requirement already satisfied: jedi<=0.17.2,>=0.10 in /usr/local/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (0.17.2)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.29)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (2.12.0)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /usr/local/lib/python3.7/site-packages (from jedi<=0.17.2,>=0.10->ipython>=4.0.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /root/.local/lib/python3.7/site-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.4.8)\n",
      "Requirement already satisfied: prometheus-client in /root/.local/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.13.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.2)\n",
      "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.9.2)\n",
      "Requirement already satisfied: argon2-cffi in /root/.local/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.3.0)\n",
      "Requirement already satisfied: nbconvert in /root/.local/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.4.1)\n",
      "Requirement already satisfied: nbformat in /root/.local/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /root/.local/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /root/.local/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.13.1)\n",
      "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.1->jupyter-client->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /root/.local/lib/python3.7/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/site-packages (from matplotlib) (1.18.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/site-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /root/.local/lib/python3.7/site-packages (from matplotlib) (4.29.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /root/.local/lib/python3.7/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/site-packages (from matplotlib) (20.9)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.10.0.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /root/.local/lib/python3.7/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.7/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.7/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.1.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /root/.local/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /root/.local/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: defusedxml in /root/.local/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: testpath in /root/.local/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.0)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /root/.local/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.10)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.4)\n",
      "Requirement already satisfied: bleach in /root/.local/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /root/.local/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /root/.local/lib/python3.7/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /root/.local/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.5.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /root/.local/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/site-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.4.1)\n",
      "Requirement already satisfied: webencodings in /root/.local/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Built-Ins:\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# External Dependencies:\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Local Dependencies:\n",
    "from util.nb import upload_in_background\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlow as TensorFlowEstimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup the SageMaker role\n",
    "role = sagemaker.get_execution_role()\n",
    "# 2. Setup the SageMaker session\n",
    "sess = sagemaker.Session()\n",
    "# 3. Setup the SageMaker default bucket\n",
    "bucket_name = sess.default_bucket()  # We'll just use the default bucket as the other examples did\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data and Upload to Amazon S3\n",
    "\n",
    "The primary data source for a SageMaker training job is (nearly) always S3 - so we should upload our training and test data there.\n",
    "\n",
    "For this exercise, we prepared a few lines of code below to help you upload the images to Amazon S3 using the [aws s3 sync](https://docs.aws.amazon.com/cli/latest/reference/s3/sync.html) CLI command.\n",
    "\n",
    "But first, let's download the image data from the Repository of Open Data on AWS and sample a subset like we did in the [Local Notebook.ipynb](Local%20Notebook.ipynb).\n",
    "\n",
    "**Check you understand** what data it's going to upload from this notebook, and where it's going to store it in S3, then start the upload running.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://fast-ai-imageclas/cifar10.tgz to ../../../tmp/cifar10/cifar10.tgz\n",
      "Training files: 50000\n",
      "Testing files:  10000\n",
      "Training files kept: 50000\n",
      "Testing files kept:  10000\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "target_path = \"/tmp/cifar10\"\n",
    "training_dir = f\"{target_path}/train\"\n",
    "testing_dir = f\"{target_path}/test\"\n",
    "\n",
    "# Download the CIFAR10 data from the Registry of Open Data on AWS\n",
    "!rm -rf {target_path}\n",
    "!mkdir -p {target_path}\n",
    "!aws s3 cp s3://fast-ai-imageclas/cifar10.tgz {target_path} --no-sign-request\n",
    "\n",
    "# Un-tar the CIFAR10 data, stripping the leading path element; this will leave us with directories\n",
    "# {target_path}/testing/ and {target_path/training/\n",
    "!tar zxf {target_path}/cifar10.tgz -C {target_path}/ --strip-components=1 --no-same-owner\n",
    "!rm -f {target_path}/cifar10.tgz\n",
    "\n",
    "# Get the list of files in the training and testing directories recursively\n",
    "train_files = sorted(list(glob.iglob(os.path.join(training_dir, \"*/*.png\"), recursive=True)))\n",
    "test_files = sorted(list(glob.iglob(os.path.join(testing_dir, \"*/*.png\"), recursive=True)))\n",
    "\n",
    "print(f\"Training files: {len(train_files)}\")\n",
    "print(f\"Testing files:  {len(test_files)}\")\n",
    "\n",
    "# Reduce the data by keeping every Nth file and dropping the rest of the files.\n",
    "reduction_factor = 1\n",
    "train_files_to_keep = train_files[::reduction_factor]\n",
    "test_files_to_keep = test_files[::reduction_factor]\n",
    "\n",
    "print(f\"Training files kept: {len(train_files_to_keep)}\")\n",
    "print(f\"Testing files kept:  {len(test_files_to_keep)}\")\n",
    "\n",
    "# Delete all the files not to be kept\n",
    "for fname in (set(train_files) ^ set(train_files_to_keep)):\n",
    "    os.remove(fname)\n",
    "\n",
    "for fname in (set(test_files) ^ set(test_files_to_keep)):\n",
    "    os.remove(fname)\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = sorted(os.listdir(training_dir))\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ⏰ **Note:** Uploading to Amazon S3 typically takes about 2-3 minutes assuming a `reduction_factor` of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "CPU times: user 354 ms, sys: 37.7 ms, total: 392 ms\n",
      "Wall time: 20.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "!aws s3 sync --quiet --delete {target_path} s3://{bucket_name}/cifar10\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check your data is uploaded by finding your bucket in the [Amazon S3 Console](https://s3.console.aws.amazon.com/s3/home). Do you see the folders of images as expected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Input (\"Channels\") Configuration\n",
    "\n",
    "The draft code has **2 data sets**: One for training, and one for test/validation. (For classification, the folder location of each image is sufficient as a label).\n",
    "\n",
    "In SageMaker terminology, each input data set is a \"channel\" and we can name them however we like... Just make sure you're consistent about what you call each one!\n",
    "\n",
    "For a simple input configuration, a channel spec might just be the S3 URI of the folder. For configuring more advanced options, there's the [s3_input](https://sagemaker.readthedocs.io/en/stable/inputs.html) class in the SageMaker SDK.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': <sagemaker.inputs.TrainingInput object at 0x7f544f6b2a50>, 'test': <sagemaker.inputs.TrainingInput object at 0x7f544f6b2990>}\n"
     ]
    }
   ],
   "source": [
    "input_mode = 'File' # 'FastFile' is not suitable on the use case given the dataset is with many small files. (< 50MB)\n",
    "\n",
    "train_channel = sagemaker.inputs.TrainingInput(f\"s3://{bucket_name}/cifar10/train\", input_mode=input_mode)\n",
    "test_channel = sagemaker.inputs.TrainingInput(f\"s3://{bucket_name}/cifar10/test\", input_mode=input_mode)\n",
    "\n",
    "inputs = { \"train\": train_channel, \"test\": test_channel }\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm (\"Estimator\") Configuration and Run\n",
    "\n",
    "Instead of loading and fitting this data here in the notebook, we'll be creating a [TensorFlow Estimator](https://sagemaker.readthedocs.io/en/stable/sagemaker.tensorflow.html#tensorflow-estimator) through the SageMaker SDK, to run the code on a separate container that can be scaled as required.\n",
    "\n",
    "The [\"Using TensorFlow with the SageMaker Python SDK\"](https://sagemaker.readthedocs.io/en/stable/using_tf.html#train-a-model-with-tensorflow) docs give a good overview of this process. You should run your estimator in **script mode** (which is easier to follow than the old default legacy mode) and as **Python 3**.\n",
    "\n",
    "**Use the [src/main.py](src/main.py) file** as your entry point to port code into - which has already been created for you with some basic hints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TensorFlowEstimator(\n",
    "    role=role,  # IAM role to run the job under - we just use the same as the notebook role\n",
    "    \n",
    "    # Framework setup:\n",
    "    entry_point=\"main.py\",  # Target script\n",
    "    source_dir=\"./src\",  # Folder to bundle, in case we want to split the code between files\n",
    "    framework_version=\"2.4\",  # TensorFlow version\n",
    "    py_version=\"py37\",  # The time to migrate away from Python 2 has long ago passed!\n",
    "\n",
    "    # Infrastructure provisioning:\n",
    "    instance_count=1,  # We haven't implemented parallelization in our script\n",
    "    instance_type=\"ml.c5.xlarge\",  # Keras should be accelerated by GPU 'ml.g4dn.xlarge'\n",
    "    max_run=20*60, # The training shouldn't take too long to run\n",
    "    # use_spot_instances=True,  # May as well use spot to save money\n",
    "    # max_wait=40*60,  # ...And we don't want to wait for ages for spot instances\n",
    "    \n",
    "    # Parameters to pass to our script:\n",
    "    hyperparameters={\n",
    "        \"epochs\": 5, \n",
    "        \"batch-size\": 128,\n",
    "    },\n",
    "    \n",
    "    # Performance/progress metrics to scrape from console output:\n",
    "    metric_definitions=[\n",
    "        { \"Name\": \"loss\", \"Regex\": \"loss: ([0-9\\\\.]+)\" },\n",
    "        { \"Name\": \"accuracy\", \"Regex\": \"acc: ([0-9\\\\.]+)\" },\n",
    "        { \"Name\": \"test:loss\", \"Regex\": \"Test.*loss=([0-9\\\\.]+)\" },\n",
    "        { \"Name\": \"test:accuracy\", \"Regex\": \"Test.*accuracy=([0-9\\\\.]+)\" },\n",
    "    ],\n",
    "    \n",
    "    # Let's keep our SageMaker records tidy by giving the training jobs a sensible name\n",
    "    base_job_name=\"cifar10-keras\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the actual training on SageMaker TrainingJob, it can be good to run it locally first using the code below. If there is any error, you can fix them first before running using SageMaker TrainingJob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-16 07:16:38.454398: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "2022-07-16 07:16:38.454512: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n",
      "2022-07-16 07:16:38.488690: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "Namespace(batch_size=128, epochs=1, model_dir='data/local-model', output_data_dir='data/local-output', test='/tmp/cifar10/test', train='/tmp/cifar10/train')\n",
      "Loading dataset...\n",
      "Loading label airplane...automobile...bird...cat...deer...dog...frog...horse...ship...truck...\n",
      "Shuffling trainset...\n",
      "Shuffling testset...\n",
      "Done!\n",
      "training data set shape: (50000, 32, 32, 3)\n",
      "channels_last\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "input_shape: (32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "n_labels: 10\n",
      "y_train shape: (50000, 10)\n",
      "Building a model...\n",
      "2022-07-16 07:16:57.328334: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX512F\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-16 07:16:57.359305: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\n",
      "2022-07-16 07:16:57.359472: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560eff2bea10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-07-16 07:16:57.359497: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-07-16 07:16:57.359623: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "[2022-07-16 07:16:57.798 tensorflow-2-3-cpu-py3-ml-m5-large-d0f05135b7af900c931425c02b74:345 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2022-07-16 07:16:58.192 tensorflow-2-3-cpu-py3-ml-m5-large-d0f05135b7af900c931425c02b74:345 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "Fitting the data...\n",
      "391/391 - 123s - loss: 1.7812 - accuracy: 0.3437 - val_loss: 1.3626 - val_accuracy: 0.5005\n",
      "Test loss: 1.362625002861023\n",
      "Test accuracy: 0.5005000233650208\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "2022-07-16 07:19:11.469157: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: data/local-model/model/1/assets\n",
      "INFO:tensorflow:Assets written to: data/local-model/model/1/assets\n",
      "CPU times: user 3.47 s, sys: 390 ms, total: 3.86 s\n",
      "Wall time: 2min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "!python3 src/main.py --train {training_dir} --test {testing_dir} --output-data-dir data/local-output --model-dir data/local-model --epochs=1 --batch-size=128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you're ready to try your script in a SageMaker training job, you can call `estimator.fit()` as we did in previous exercises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-16 07:39:15 Starting - Starting the training job...\n",
      "2022-07-16 07:39:37 Starting - Preparing the instances for trainingProfilerReport-1657957155: InProgress\n",
      "............\n",
      "2022-07-16 07:41:27 Downloading - Downloading input data.............................................\n",
      "2022-07-16 07:49:09 Training - Training image download completed. Training in progress.\u001b[34m2022-07-16 07:49:05.116881: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2022-07-16 07:49:05.128973: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2022-07-16 07:49:05.319007: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2022-07-16 07:49:09,585 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2022-07-16 07:49:09,592 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-07-16 07:49:10,083 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.7 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 21.2.4; however, version 22.1.2 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2022-07-16 07:49:11,591 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-07-16 07:49:11,609 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-07-16 07:49:11,627 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-07-16 07:49:11,637 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 128,\n",
      "        \"epochs\": 10,\n",
      "        \"model_dir\": \"s3://sagemaker-ap-southeast-2-452533547478/cifar10-keras-2022-07-16-07-39-15-397/model\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"cifar10-keras-2022-07-16-07-39-15-397\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-southeast-2-452533547478/cifar10-keras-2022-07-16-07-39-15-397/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"main\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.c5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.c5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"main.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":128,\"epochs\":10,\"model_dir\":\"s3://sagemaker-ap-southeast-2-452533547478/cifar10-keras-2022-07-16-07-39-15-397/model\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=main.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=main\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-southeast-2-452533547478/cifar10-keras-2022-07-16-07-39-15-397/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":128,\"epochs\":10,\"model_dir\":\"s3://sagemaker-ap-southeast-2-452533547478/cifar10-keras-2022-07-16-07-39-15-397/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"cifar10-keras-2022-07-16-07-39-15-397\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-southeast-2-452533547478/cifar10-keras-2022-07-16-07-39-15-397/source/sourcedir.tar.gz\",\"module_name\":\"main\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"main.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"128\",\"--epochs\",\"10\",\"--model_dir\",\"s3://sagemaker-ap-southeast-2-452533547478/cifar10-keras-2022-07-16-07-39-15-397/model\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=128\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=s3://sagemaker-ap-southeast-2-452533547478/cifar10-keras-2022-07-16-07-39-15-397/model\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python37.zip:/usr/local/lib/python3.7:/usr/local/lib/python3.7/lib-dynload:/usr/local/lib/python3.7/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.7 main.py --batch-size 128 --epochs 10 --model_dir s3://sagemaker-ap-southeast-2-452533547478/cifar10-keras-2022-07-16-07-39-15-397/model\u001b[0m\n",
      "\u001b[34mNamespace(batch_size=128, epochs=10, model_dir='/opt/ml/model', output_data_dir='/opt/ml/output/data', test='/opt/ml/input/data/test', train='/opt/ml/input/data/train')\u001b[0m\n",
      "\u001b[34mLoading dataset...\u001b[0m\n",
      "\u001b[34mLoading label airplane...automobile...bird...cat...deer...dog...frog...horse...ship...truck...\u001b[0m\n",
      "\u001b[34mShuffling trainset...\u001b[0m\n",
      "\u001b[34mShuffling testset...\u001b[0m\n",
      "\u001b[34mDone!\u001b[0m\n",
      "\u001b[34mtraining data set shape: (50000, 32, 32, 3)\u001b[0m\n",
      "\u001b[34mchannels_last\u001b[0m\n",
      "\u001b[34mx_train shape: (50000, 32, 32, 3)\u001b[0m\n",
      "\u001b[34minput_shape: (32, 32, 3)\u001b[0m\n",
      "\u001b[34m50000 train samples\u001b[0m\n",
      "\u001b[34m10000 test samples\u001b[0m\n",
      "\u001b[34mn_labels: 10\u001b[0m\n",
      "\u001b[34my_train shape: (50000, 10)\u001b[0m\n",
      "\u001b[34mBuilding a model...\u001b[0m\n",
      "\u001b[34m[2022-07-16 07:49:42.684 ip-10-0-75-123.ap-southeast-2.compute.internal:33 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-07-16 07:49:42.894 ip-10-0-75-123.ap-southeast-2.compute.internal:33 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34mFitting the data...\u001b[0m\n",
      "\u001b[34m[2022-07-16 07:49:43.624 ip-10-0-75-123.ap-southeast-2.compute.internal:33 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-07-16 07:49:43.624 ip-10-0-75-123.ap-southeast-2.compute.internal:33 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2022-07-16 07:49:43.625 ip-10-0-75-123.ap-southeast-2.compute.internal:33 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2022-07-16 07:49:43.625 ip-10-0-75-123.ap-southeast-2.compute.internal:33 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2022-07-16 07:49:43.625 ip-10-0-75-123.ap-southeast-2.compute.internal:33 INFO hook.py:425] Monitoring the collections: losses, sm_metrics, metrics\u001b[0m\n",
      "\u001b[34mEpoch 1/10\u001b[0m\n",
      "\u001b[34m[2022-07-16 07:49:43.717 ip-10-0-75-123.ap-southeast-2.compute.internal:33 INFO hook.py:425] Monitoring the collections: losses, sm_metrics, metrics\u001b[0m\n",
      "\u001b[34m391/391 - 84s - loss: 1.7560 - accuracy: 0.3571 - val_loss: 1.3226 - val_accuracy: 0.5342\u001b[0m\n",
      "\u001b[34mEpoch 2/10\u001b[0m\n",
      "\u001b[34m391/391 - 81s - loss: 1.2970 - accuracy: 0.5368 - val_loss: 1.0625 - val_accuracy: 0.6242\u001b[0m\n",
      "\u001b[34mEpoch 3/10\u001b[0m\n",
      "\u001b[34m391/391 - 80s - loss: 1.0555 - accuracy: 0.6317 - val_loss: 0.9015 - val_accuracy: 0.6839\u001b[0m\n",
      "\u001b[34mEpoch 4/10\u001b[0m\n",
      "\u001b[34m391/391 - 85s - loss: 0.9097 - accuracy: 0.6863 - val_loss: 0.8299 - val_accuracy: 0.7102\u001b[0m\n",
      "\u001b[34mEpoch 5/10\u001b[0m\n",
      "\u001b[34m391/391 - 80s - loss: 0.7955 - accuracy: 0.7252 - val_loss: 0.7700 - val_accuracy: 0.7278\u001b[0m\n",
      "\u001b[34mEpoch 6/10\u001b[0m\n",
      "\u001b[34m391/391 - 81s - loss: 0.7169 - accuracy: 0.7536 - val_loss: 0.7656 - val_accuracy: 0.7313\u001b[0m\n",
      "\u001b[34mEpoch 7/10\u001b[0m\n",
      "\u001b[34m391/391 - 82s - loss: 0.6528 - accuracy: 0.7733 - val_loss: 0.6910 - val_accuracy: 0.7667\u001b[0m\n",
      "\u001b[34mEpoch 8/10\u001b[0m\n",
      "\u001b[34m391/391 - 81s - loss: 0.5876 - accuracy: 0.7960 - val_loss: 0.6364 - val_accuracy: 0.7839\u001b[0m\n",
      "\u001b[34mEpoch 9/10\u001b[0m\n",
      "\u001b[34m391/391 - 81s - loss: 0.5403 - accuracy: 0.8120 - val_loss: 0.6366 - val_accuracy: 0.7820\u001b[0m\n",
      "\u001b[34mEpoch 10/10\u001b[0m\n",
      "ProfilerReport-1657957155: Stopped\n",
      "\u001b[34m391/391 - 82s - loss: 0.4856 - accuracy: 0.8300 - val_loss: 0.6506 - val_accuracy: 0.7853\u001b[0m\n",
      "\u001b[34mTest loss: 0.650593101978302\u001b[0m\n",
      "\u001b[34mTest accuracy: 0.7853000164031982\u001b[0m\n",
      "\u001b[34m2022-07-16 07:49:11.918783: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2022-07-16 07:49:11.918897: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2022-07-16 07:49:11.948901: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2022-07-16 08:03:29.389108: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets written to: /opt/ml/model/model/1/assets\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets written to: /opt/ml/model/model/1/assets\u001b[0m\n",
      "\u001b[34m2022-07-16 08:03:30,826 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-07-16 08:03:47 Uploading - Uploading generated training model\n",
      "2022-07-16 08:03:47 Completed - Training job completed\n",
      "Training seconds: 1347\n",
      "Billable seconds: 1347\n",
      "CPU times: user 2.58 s, sys: 65 ms, total: 2.64 s\n",
      "Wall time: 24min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "estimator.fit(inputs)\n",
    "\n",
    "# Note: As configured, this job took about 12 clock minutes (but only ~80 billable seconds) to run,\n",
    "# reaching a test accuracy of ~70%. The majority of the time is the download of images to the\n",
    "# container - which could be significantly optimized as discussed later in \"Further Improvements\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy and Use Your Model (Real-Time Inference)\n",
    "\n",
    "If your training job has completed; and saved the model in the correct TensorFlow Serving-compatible format; it should now be pretty simple to deploy the model to a real-time endpoint.\n",
    "\n",
    "You can achieve this with the [Estimator API](https://sagemaker.readthedocs.io/en/stable/estimators.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "update_endpoint is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(\n",
    "    # Low request volume, tiny model = tiny infrastructure is fine:\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.t2.medium\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing the architecture from the example notebook, we set up the model to accept **batches** of **32x32x3** image tensors with **normalized 0-1 pixel values** and a **color channel dimension** (which either came in front or behind the image dimensions, depending on the value of `K.image_data_format()`)\n",
    "\n",
    "Assuming you haven't added any custom pre-processing to our model source code (to accept e.g. encoded JPEGs/PNGs, or arbitrary shapes), we'll need to replicate that same format when we use our endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the result via calling realtime endpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "# Choose an image:\n",
    "label = \"airplane\"\n",
    "index = 0\n",
    "filename = os.listdir(f\"{testing_dir}/{label}\")[index]\n",
    "\n",
    "# Load the image:\n",
    "img = tf.keras.preprocessing.image.img_to_array(\n",
    "    Image.open(f\"{testing_dir}/{label}/{filename}\")\n",
    ")\n",
    "img = img / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result confidences: [0.836487949, 0.109619528, 0.00187871011, 0.00175143196, 0.000468814513, 6.77112766e-05, 0.000122061858, 3.17847916e-05, 0.0172428116, 0.0323293284] and the related argmax: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Expand out the \"batch\" dimension, and send to the model:\n",
    "result = predictor.predict(np.expand_dims(img, axis=0))['predictions'][0]\n",
    "print(f\"Result confidences: {result} and the related argmax: {np.argmax(result)}\")\n",
    "\n",
    "# Plot the result:\n",
    "plt.figure(figsize=(3, 3))\n",
    "fig = plt.subplot(1, 1, 1)\n",
    "ax = plt.imshow(np.squeeze(img), cmap=\"gray\")\n",
    "fig.set_title(f\"Predicted class: {labels[np.argmax(result)]}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.00590526732,\n",
       "  0.0298038349,\n",
       "  0.000200674927,\n",
       "  3.53738e-05,\n",
       "  2.39466317e-06,\n",
       "  4.75819797e-06,\n",
       "  4.54125038e-05,\n",
       "  7.60795911e-06,\n",
       "  0.0104717789,\n",
       "  0.953522861],\n",
       " 0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['predictions'][0], np.argmax(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Improvements\n",
    "\n",
    "If you've got the basic train/deploy/call cycle working, congratulations! This core pattern of experimenting in the notebook but executing jobs on scalable hardware is at the heart of the SageMaker data science workflow.\n",
    "\n",
    "There are still plenty of ways we can use the tools better though: Read on for the next challenges!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Cut training costs easily with SageMaker Managed Spot Mode\n",
    "\n",
    "AWS Spot Instances let you take advantage of unused capacity in the AWS cloud, at up to a 90% discount versus standard on-demand pricing! For small jobs like this, taking advantage of this discount is as easy as adding a couple of parameters to the Estimator constructor:\n",
    "\n",
    "https://sagemaker.readthedocs.io/en/stable/estimators.html\n",
    "\n",
    "Note that in general, spot capacity is offered at a discounted rate because it's interruptible based on instantaneous demand... Longer-running training jobs should implement checkpoint saving and loading, so that they can efficiently resume if interrupted part way through. More information can be found on the [Managed Spot Training in Amazon SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.html) page of the [SageMaker Developer Guide](https://docs.aws.amazon.com/sagemaker/latest/dg/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Parameterize your algorithm\n",
    "\n",
    "Being able to change the parameters of your algorithm at run-time (without modifying the `main.py` script each time) is helpful for making your code more re-usable... But even more so because it's a pre-requisite for automatic hyperparameter tuning!\n",
    "\n",
    "Job parameter parsing should ideally be factored into a separate function, and as a best practice should accept setting values through **both** command line flags (as demonstrated in the [official MXNet MNIST example](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/hyperparameter_tuning/mxnet_mnist/mnist.py)) **and** the [SageMaker Hyperparameter environment variable(s)](https://docs.aws.amazon.com/sagemaker/latest/dg/docker-container-environmental-variables-user-scripts.html). Perhaps the official MXNet example could be improved by setting environment-variable-driven defaults to the algorithm hyperparameters, the same as it already does for channels?\n",
    "\n",
    "Refactor your job to accept **epochs** and **batch size** as optional parameters, and show how you can set these before each training run through the [Estimator API](https://sagemaker.readthedocs.io/en/stable/estimators.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tune your network hyperparameters\n",
    "\n",
    "Re-use the same approach as before to parameterize some features in the structure of your network: Perhaps the sizes of the `Conv2D` kernels? The number, type, node count, or activation function of layers in the network? No need to stray too far away from the sample architecture!\n",
    "\n",
    "Instead of manually (or programmatically) calling `estimator.fit()` with different hyperparameters each time, we can use SageMaker's Bayesian Hyperparameter Tuning functionality to explore the space more efficiently!\n",
    "\n",
    "The SageMaker SDK Docs give a great [overview](https://sagemaker.readthedocs.io/en/stable/overview.html#sagemaker-automatic-model-tuning) of using the HyperparameterTuner, which you can refer to if you get stuck.\n",
    "\n",
    "First, we'll need to define a specific **metric** to optimize for, which is really a specification of how to scrape metric values from the algorithm's console logs. \n",
    "\n",
    "Next, use the [\\*Parameter](https://sagemaker.readthedocs.io/en/stable/tuner.html) classes (`ContinuousParameter`, `IntegerParameter` and `CategoricalParameter`) to define appropriate ranges for the hyperparameters whose combination you want to optimize.\n",
    "\n",
    "With the original estimator, target metric and parameter ranges defined, you'll be able to create a [HyperparameterTuner](https://sagemaker.readthedocs.io/en/stable/tuner.html) and use that to start a hyperparameter tuning job instead of a single model training job.\n",
    "\n",
    "Pay attention to likely run time and resource consumption when selecting the maximum total number of training jobs and maximum parallel jobs of your hyperparameter tuning run... You can always view and cancel ongoing hyperparameter tuning jobs through the SageMaker Console.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Challenges\n",
    "\n",
    "If you have time, the following challenges are trickier, and might stretch your SageMaker knowledge even further!\n",
    "\n",
    "**Batch Transform / Additional Inference Formats**: As discussed in this notebook, the deployed endpoint expects a particular tensor data format for requests... This complicates the usually-simple task of re-purposing the same model for batch inference (since our data in S3 is in JPEG format). The SageMaker TensorFlow SDK docs provide guidance on accepting custom formats in the [\"Create Python Scripts for Custom Input and Output Formats\"](https://sagemaker.readthedocs.io/en/stable/using_tf.html#create-python-scripts-for-custom-input-and-output-formats) section. If you can refactor your algorithm to accept JPEG requests when deployed as a real-time endpoint, you'll be able to run it as a batch [Transformer](https://sagemaker.readthedocs.io/en/stable/transformer.html) against images in S3 with a simple `estimator.transformer()` call.\n",
    "\n",
    "**Optimized Training Formats**: A dataset like this (containing many tiny objects) may take much less time to load in to the algorithm if we either converted it to the standard Numpy format that Keras distributes it in (just 4 files X_train, Y_train, X_test, Y_test); or *streaming* the data with [SageMaker Pipe Mode](https://aws.amazon.com/blogs/machine-learning/using-pipe-input-mode-for-amazon-sagemaker-algorithms/), instead of downloading it up-front.\n",
    "\n",
    "**Experiment Tracking**: The [SageMaker Experiments](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html) feature gives a more structured way to track trials across multiple related experiments (for example, different HPO runs, or between HPO and regular model training jobs). You can use the [official SageMaker Experiments Example](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/sagemaker-experiments) for guidance on how to track the experiments in this notebook... and should note that the [SageMaker Experiments SDK Docs](https://sagemaker-experiments.readthedocs.io/en/latest/) are maintained separately, since it's a different Python module.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean-Up\n",
    "\n",
    "Remember to clean up any persistent resources that aren't needed anymore to save costs: The most significant of these are real-time prediction endpoints, and this SageMaker Notebook Instance.\n",
    "\n",
    "The SageMaker SDK [Predictor](https://sagemaker.readthedocs.io/en/stable/predictors.html) class provides an interface to clean up real-time prediction endpoints; and SageMaker Notebook Instances can be stopped through the SageMaker Console when you're finished.\n",
    "\n",
    "You might also like to clean up any S3 buckets / content we created, to prevent ongoing storage costs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.3 Python 3.7 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-2:452832661640:image/tensorflow-2.3-cpu-py37-ubuntu18.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
